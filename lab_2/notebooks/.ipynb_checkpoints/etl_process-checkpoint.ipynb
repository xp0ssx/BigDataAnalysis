{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно подключились к PostgreSQL\n",
      "Количество строк в исходной таблице: 10000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PetStoreETL\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \n",
    "            \"/home/jovyan/work/postgresql-42.7.1.jar:/home/jovyan/work/clickhouse-jdbc-0.4.6-all.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \n",
    "            \"/home/jovyan/work/postgresql-42.7.1.jar:/home/jovyan/work/clickhouse-jdbc-0.4.6-all.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "postgres_properties = {\n",
    "    \"url\": \"jdbc:postgresql://postgres_pet_store:5432/pet_store_lab_2\",\n",
    "    \"driver\": \"org.postgresql.Driver\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"password\"\n",
    "}\n",
    "\n",
    "df = spark.read.jdbc(\n",
    "    url=postgres_properties[\"url\"],\n",
    "    table=\"mock_data\",\n",
    "    properties=postgres_properties\n",
    ")\n",
    "print(\"Успешно подключились к PostgreSQL\")\n",
    "print(f\"Количество строк в исходной таблице: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все таблицы успешно очищены\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tables = [\"fact_sales\", \"dim_customer\", \"dim_seller\", \"dim_product\", \n",
    "              \"dim_store\", \"dim_supplier\", \"dim_date\"]\n",
    "    \n",
    "    for table in tables:\n",
    "        # Используем подзапрос, который вернет результат после выполнения DELETE\n",
    "        spark.read.jdbc(\n",
    "            url=postgres_properties[\"url\"],\n",
    "            table=f\"(SELECT 1 as col1 FROM {table} WHERE 1=0) cleanup\",\n",
    "            properties=postgres_properties\n",
    "        )\n",
    "        \n",
    "        # Теперь выполняем DELETE через write.jdbc\n",
    "        empty_df = spark.createDataFrame([], \"col1 INT\")\n",
    "        empty_df.write \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .jdbc(url=postgres_properties[\"url\"],\n",
    "                 table=table,\n",
    "                 properties=postgres_properties)\n",
    "    \n",
    "    print(\"Все таблицы успешно очищены\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при очистке таблиц: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обработка измерения Customer...\n",
      "Количество уникальных покупателей: 1000\n",
      "Измерение Customer успешно загружено\n",
      "\n",
      "Обработка измерения Seller...\n",
      "Количество уникальных продавцов: 1000\n",
      "Измерение Seller успешно загружено\n",
      "\n",
      "Обработка измерения Product...\n",
      "Количество уникальных продуктов: 1000\n",
      "Измерение Product успешно загружено\n",
      "\n",
      "Обработка измерения Store...\n",
      "Количество уникальных магазинов: 383\n",
      "Измерение Store успешно загружено\n",
      "\n",
      "Обработка измерения Supplier...\n",
      "Количество уникальных поставщиков: 383\n",
      "Измерение Supplier успешно загружено\n",
      "\n",
      "Обработка измерения Date...\n",
      "Количество уникальных дат: 364\n",
      "Измерение Date успешно загружено\n",
      "\n",
      "Проверка результатов дедупликации:\n",
      "\n",
      "Анализ измерения Store:\n",
      "Количество записей: 383\n",
      "\n",
      "Распределение по странам:\n",
      "+-------------+-----+\n",
      "|store_country|count|\n",
      "+-------------+-----+\n",
      "|        China|   73|\n",
      "|    Indonesia|   39|\n",
      "|       Russia|   24|\n",
      "|  Philippines|   15|\n",
      "|     Portugal|   15|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Анализ измерения Supplier:\n",
      "Количество записей: 383\n",
      "\n",
      "Распределение по странам:\n",
      "+----------------+-----+\n",
      "|supplier_country|count|\n",
      "+----------------+-----+\n",
      "|           China|   78|\n",
      "|       Indonesia|   32|\n",
      "|     Philippines|   22|\n",
      "|          Russia|   21|\n",
      "|          Brazil|   16|\n",
      "+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Измерение Customer\n",
    "print(\"\\nОбработка измерения Customer...\")\n",
    "dim_customer_df = df.select(\n",
    "    'sale_customer_id',\n",
    "    'customer_first_name',\n",
    "    'customer_last_name',\n",
    "    'customer_age',\n",
    "    'customer_email',\n",
    "    'customer_country',\n",
    "    'customer_postal_code',\n",
    "    'customer_pet_type',\n",
    "    'customer_pet_name',\n",
    "    'customer_pet_breed'\n",
    ").dropDuplicates(['sale_customer_id']) \\\n",
    " .withColumnRenamed('sale_customer_id', 'customer_id')\n",
    "\n",
    "print(f\"Количество уникальных покупателей: {dim_customer_df.count()}\")\n",
    "dim_customer_df.write \\\n",
    "    .jdbc(url=postgres_properties[\"url\"],\n",
    "          table=\"dim_customer\",\n",
    "          mode=\"overwrite\",\n",
    "          properties=postgres_properties)\n",
    "print(\"Измерение Customer успешно загружено\")\n",
    "\n",
    "# 2. Измерение Seller\n",
    "print(\"\\nОбработка измерения Seller...\")\n",
    "dim_seller_df = df.select(\n",
    "    'sale_seller_id',\n",
    "    'seller_first_name',\n",
    "    'seller_last_name',\n",
    "    'seller_email',\n",
    "    'seller_country',\n",
    "    'seller_postal_code'\n",
    ").dropDuplicates(['sale_seller_id']) \\\n",
    " .withColumnRenamed('sale_seller_id', 'seller_id')\n",
    "\n",
    "print(f\"Количество уникальных продавцов: {dim_seller_df.count()}\")\n",
    "dim_seller_df.write \\\n",
    "    .jdbc(url=postgres_properties[\"url\"],\n",
    "          table=\"dim_seller\",\n",
    "          mode=\"overwrite\",\n",
    "          properties=postgres_properties)\n",
    "print(\"Измерение Seller успешно загружено\")\n",
    "\n",
    "# 3. Измерение Product\n",
    "print(\"\\nОбработка измерения Product...\")\n",
    "dim_product_df = df.select(\n",
    "    'sale_product_id',\n",
    "    'product_name',\n",
    "    'product_category',\n",
    "    'pet_category',\n",
    "    'product_weight',\n",
    "    'product_color',\n",
    "    'product_size',\n",
    "    'product_brand',\n",
    "    'product_material',\n",
    "    'product_description',\n",
    "    'product_rating',\n",
    "    'product_reviews',\n",
    "    'product_release_date',\n",
    "    'product_expiry_date'\n",
    ").dropDuplicates(['sale_product_id']) \\\n",
    " .withColumnRenamed('sale_product_id', 'product_id')\n",
    "\n",
    "print(f\"Количество уникальных продуктов: {dim_product_df.count()}\")\n",
    "dim_product_df.write \\\n",
    "    .jdbc(url=postgres_properties[\"url\"],\n",
    "          table=\"dim_product\",\n",
    "          mode=\"overwrite\",\n",
    "          properties=postgres_properties)\n",
    "print(\"Измерение Product успешно загружено\")\n",
    "\n",
    "# 4. Измерение Store\n",
    "print(\"\\nОбработка измерения Store...\")\n",
    "# Создаем временное представление\n",
    "df.createOrReplaceTempView(\"source_data\")\n",
    "\n",
    "store_dedup_sql = \"\"\"\n",
    "WITH store_locations AS (\n",
    "    SELECT DISTINCT\n",
    "        store_name,\n",
    "        store_city,\n",
    "        store_country,\n",
    "        store_location,\n",
    "        store_state,\n",
    "        store_phone,\n",
    "        store_email,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY store_name\n",
    "            ORDER BY store_email\n",
    "        ) as rn\n",
    "    FROM source_data\n",
    ")\n",
    "SELECT \n",
    "    store_name,\n",
    "    store_location,\n",
    "    store_city,\n",
    "    store_state,\n",
    "    store_country,\n",
    "    store_phone,\n",
    "    store_email\n",
    "FROM store_locations\n",
    "WHERE rn = 1\n",
    "\"\"\"\n",
    "\n",
    "dim_store_df = spark.sql(store_dedup_sql) \\\n",
    "    .withColumn('store_id', monotonically_increasing_id())\n",
    "\n",
    "print(f\"Количество уникальных магазинов: {dim_store_df.count()}\")\n",
    "dim_store_df.write \\\n",
    "    .jdbc(url=postgres_properties[\"url\"],\n",
    "          table=\"dim_store\",\n",
    "          mode=\"overwrite\",\n",
    "          properties=postgres_properties)\n",
    "print(\"Измерение Store успешно загружено\")\n",
    "\n",
    "# 5. Измерение Supplier\n",
    "print(\"\\nОбработка измерения Supplier...\")\n",
    "supplier_dedup_sql = \"\"\"\n",
    "WITH supplier_locations AS (\n",
    "    SELECT DISTINCT\n",
    "        supplier_name,\n",
    "        supplier_city,\n",
    "        supplier_country,\n",
    "        supplier_contact,\n",
    "        supplier_email,\n",
    "        supplier_phone,\n",
    "        supplier_address,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY supplier_name\n",
    "            ORDER BY supplier_email\n",
    "        ) as rn\n",
    "    FROM source_data\n",
    ")\n",
    "SELECT \n",
    "    supplier_name,\n",
    "    supplier_contact,\n",
    "    supplier_email,\n",
    "    supplier_phone,\n",
    "    supplier_address,\n",
    "    supplier_city,\n",
    "    supplier_country\n",
    "FROM supplier_locations\n",
    "WHERE rn = 1\n",
    "\"\"\"\n",
    "\n",
    "dim_supplier_df = spark.sql(supplier_dedup_sql) \\\n",
    "    .withColumn('supplier_id', monotonically_increasing_id())\n",
    "\n",
    "print(f\"Количество уникальных поставщиков: {dim_supplier_df.count()}\")\n",
    "dim_supplier_df.write \\\n",
    "    .jdbc(url=postgres_properties[\"url\"],\n",
    "          table=\"dim_supplier\",\n",
    "          mode=\"overwrite\",\n",
    "          properties=postgres_properties)\n",
    "print(\"Измерение Supplier успешно загружено\")\n",
    "\n",
    "# 6. Измерение Date\n",
    "print(\"\\nОбработка измерения Date...\")\n",
    "dim_date_df = df.select('sale_date').distinct() \\\n",
    "    .withColumn('date_id', col('sale_date')) \\\n",
    "    .withColumn('year', year('sale_date')) \\\n",
    "    .withColumn('month', month('sale_date')) \\\n",
    "    .withColumn('day', dayofmonth('sale_date')) \\\n",
    "    .withColumn('quarter', quarter('sale_date')) \\\n",
    "    .withColumn('is_weekend', dayofweek('sale_date').isin([1, 7]))\n",
    "\n",
    "print(f\"Количество уникальных дат: {dim_date_df.count()}\")\n",
    "dim_date_df.write \\\n",
    "    .jdbc(url=postgres_properties[\"url\"],\n",
    "          table=\"dim_date\",\n",
    "          mode=\"overwrite\",\n",
    "          properties=postgres_properties)\n",
    "print(\"Измерение Date успешно загружено\")\n",
    "\n",
    "print(\"\\nПроверка результатов дедупликации:\")\n",
    "\n",
    "print(\"\\nАнализ измерения Store:\")\n",
    "print(\"Количество записей:\", dim_store_df.count())\n",
    "print(\"\\nРаспределение по странам:\")\n",
    "dim_store_df.groupBy('store_country') \\\n",
    "    .count() \\\n",
    "    .orderBy(desc('count')) \\\n",
    "    .show(5)\n",
    "\n",
    "print(\"\\nАнализ измерения Supplier:\")\n",
    "print(\"Количество записей:\", dim_supplier_df.count())\n",
    "print(\"\\nРаспределение по странам:\")\n",
    "dim_supplier_df.groupBy('supplier_country') \\\n",
    "    .count() \\\n",
    "    .orderBy(desc('count')) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создание таблицы фактов продаж...\n",
      "\n",
      "Проверка качества данных в таблице фактов:\n",
      "Общее количество строк: 10000\n",
      "+-----------------+---------------+----------------+--------------+-----------------+-------------+\n",
      "|null_customer_ids|null_seller_ids|null_product_ids|null_store_ids|null_supplier_ids|null_date_ids|\n",
      "+-----------------+---------------+----------------+--------------+-----------------+-------------+\n",
      "|                0|              0|               0|             0|                0|            0|\n",
      "+-----------------+---------------+----------------+--------------+-----------------+-------------+\n",
      "\n",
      "Таблица фактов успешно создана и сохранена\n",
      "\n",
      "Пример данных из таблицы фактов:\n",
      "+-----------+---------+----------+--------+-----------+----------+-------------+----------------+----------+\n",
      "|customer_id|seller_id|product_id|store_id|supplier_id|   date_id|sale_quantity|sale_total_price|unit_price|\n",
      "+-----------+---------+----------+--------+-----------+----------+-------------+----------------+----------+\n",
      "|        226|      226|       226|     213|        219|2021-04-27|            4|           45.34|     52.06|\n",
      "|        185|      185|       185|      46|        201|2021-08-17|            1|          311.50|     82.35|\n",
      "|          2|        2|         2|     162|        176|2021-11-13|           10|          484.61|     48.70|\n",
      "|        247|      247|       247|     247|          4|2021-08-07|            1|          357.64|     64.68|\n",
      "|        307|      307|       307|      95|        329|2021-12-05|            5|          195.96|     49.95|\n",
      "+-----------+---------+----------+--------+-----------+----------+-------------+----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Статистика по продажам:\n",
      "+-----------+-------------+---------------------+--------------+\n",
      "|total_sales|total_revenue|avg_quantity_per_sale|avg_unit_price|\n",
      "+-----------+-------------+---------------------+--------------+\n",
      "|      10000|   2529852.12|               5.4623|     50.816842|\n",
      "+-----------+-------------+---------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Создание таблицы фактов продаж...\")\n",
    "\n",
    "dim_store_df.createOrReplaceTempView(\"dim_store\")\n",
    "dim_supplier_df.createOrReplaceTempView(\"dim_supplier\")\n",
    "dim_date_df.createOrReplaceTempView(\"dim_date\")\n",
    "\n",
    "fact_sales_sql = \"\"\"\n",
    "WITH store_mapping AS (\n",
    "    SELECT \n",
    "        s.store_name,\n",
    "        s.store_city,\n",
    "        s.store_country,\n",
    "        s.store_id\n",
    "    FROM dim_store s\n",
    "),\n",
    "supplier_mapping AS (\n",
    "    SELECT \n",
    "        s.supplier_name,\n",
    "        s.supplier_city,\n",
    "        s.supplier_country,\n",
    "        s.supplier_id\n",
    "    FROM dim_supplier s\n",
    ")\n",
    "SELECT \n",
    "    f.sale_customer_id as customer_id,\n",
    "    f.sale_seller_id as seller_id,\n",
    "    f.sale_product_id as product_id,\n",
    "    sm.store_id,\n",
    "    sup.supplier_id,\n",
    "    d.date_id,\n",
    "    f.sale_quantity,\n",
    "    f.sale_total_price,\n",
    "    f.product_price as unit_price,\n",
    "    f.product_rating,\n",
    "    f.product_reviews\n",
    "FROM source_data f\n",
    "LEFT JOIN store_mapping sm ON \n",
    "    LOWER(TRIM(f.store_name)) = LOWER(TRIM(sm.store_name))\n",
    "LEFT JOIN supplier_mapping sup ON \n",
    "    LOWER(TRIM(f.supplier_name)) = LOWER(TRIM(sup.supplier_name))\n",
    "LEFT JOIN dim_date d ON \n",
    "    f.sale_date = d.date_id\n",
    "\"\"\"\n",
    "\n",
    "fact_sales_df = spark.sql(fact_sales_sql)\n",
    "\n",
    "print(\"\\nПроверка качества данных в таблице фактов:\")\n",
    "print(f\"Общее количество строк: {fact_sales_df.count()}\")\n",
    "\n",
    "null_check = fact_sales_df.select([\n",
    "    sum(when(col('customer_id').isNull(), 1).otherwise(0)).alias('null_customer_ids'),\n",
    "    sum(when(col('seller_id').isNull(), 1).otherwise(0)).alias('null_seller_ids'),\n",
    "    sum(when(col('product_id').isNull(), 1).otherwise(0)).alias('null_product_ids'),\n",
    "    sum(when(col('store_id').isNull(), 1).otherwise(0)).alias('null_store_ids'),\n",
    "    sum(when(col('supplier_id').isNull(), 1).otherwise(0)).alias('null_supplier_ids'),\n",
    "    sum(when(col('date_id').isNull(), 1).otherwise(0)).alias('null_date_ids')\n",
    "])\n",
    "null_check.show()\n",
    "\n",
    "fact_sales_df.write \\\n",
    "    .jdbc(url=postgres_properties[\"url\"],\n",
    "          table=\"fact_sales\",\n",
    "          mode=\"overwrite\",\n",
    "          properties=postgres_properties)\n",
    "print(\"Таблица фактов успешно создана и сохранена\")\n",
    "\n",
    "print(\"\\nПример данных из таблицы фактов:\")\n",
    "fact_sales_df.select(\n",
    "    'customer_id',\n",
    "    'seller_id',\n",
    "    'product_id',\n",
    "    'store_id',\n",
    "    'supplier_id',\n",
    "    'date_id',\n",
    "    'sale_quantity',\n",
    "    'sale_total_price',\n",
    "    'unit_price'\n",
    ").show(5)\n",
    "\n",
    "print(\"\\nСтатистика по продажам:\")\n",
    "fact_sales_df.select(\n",
    "    count('*').alias('total_sales'),\n",
    "    sum('sale_total_price').alias('total_revenue'),\n",
    "    avg('sale_quantity').alias('avg_quantity_per_sale'),\n",
    "    avg('unit_price').alias('avg_unit_price')\n",
    ").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
